{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b3dd0d5-f677-435c-82e1-08aa4602b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "torch.cuda.set_device(2)\n",
    "_exp_name = \"pre_semi_spin\"\n",
    "number_class=101\n",
    "a_style='all spins'\n",
    "a_type_1='all spins'\n",
    "a_type_2='a+0.94_shi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35b4365-8a0b-4448-900a-6af7fd5d3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "\n",
    "# This is for the progress bar.\n",
    "from tqdm.auto import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "752619b8-79b7-4b49-a262-2ca6ff5ccf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "myseed = 1023  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7eb46a1-3e5e-4401-a5ca-e33d6d330a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DomCheng/miniconda3/envs/mas/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/DomCheng/miniconda3/envs/mas/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "# 載入預先訓練的 ResNet-18 模型\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # \"cuda\" only when GPUs are available.\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# 將全連接層（分類層）修改為輸出 10 類的層\n",
    "model.fc = nn.Linear(model.fc.in_features, number_class)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8b64493-8f53-4df3-a38d-7a005afee5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=101, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best = model.to(device)\n",
    "model_best.load_state_dict(torch.load(f\"{_exp_name}_{myseed}_best.ckpt\"))\n",
    "model_best.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bb182e4-b2c7-4f60-b25f-58ac4f2d5aac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "#INTER_LINEAR – a bilinear interpolation (used by default)\n",
    "\n",
    "def test_img(filename):\n",
    "    Rh_data = []\n",
    "    IMG_SIZE = 224\n",
    "    labels = []\n",
    "    \n",
    "    \n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "        # 組合完整的檔案路徑\n",
    "        file_path = os.path.join(filename)\n",
    "\n",
    "    # 讀取照片\n",
    "    img = cv2.imread(file_path)\n",
    "\n",
    "    # 確保成功讀取照片\n",
    "    if img is not None:\n",
    "        # 將照片 resize 到指定的尺寸\n",
    "        resized_img = cv2.resize(img, (224, 224),interpolation=cv2.INTER_LINEAR)\n",
    "        #resized_img=resized_img/255\n",
    "        #resized_img[0] = (resized_img[0]-0.485)/0.229\n",
    "        #resized_img[1] = (resized_img[1]-0.456)/0.224\n",
    "        #resized_img[2] = (resized_img[2]-0.406)/0.225\n",
    "\n",
    "        # 將 resize 後的照片加入列表\n",
    "        Rh_data.append(resized_img)\n",
    "    else:\n",
    "        print(f\"無法讀取照片: {file_path}\")\n",
    "                \n",
    "    # 使用正則表達式匹配檔案名稱中的數字部分，並轉換為浮點數\n",
    "    match = re.search(r'a([\\d.]+)_', filename)\n",
    "    if match:\n",
    "        label = float(match.group(1))\n",
    "        label=label*100\n",
    "        labels.append(label)\n",
    "\n",
    "    \n",
    "    return Rh_data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fbe4e71-c1de-42bd-b974-dd7184431100",
   "metadata": {},
   "outputs": [],
   "source": [
    "u94_Rh1_data,u94_Rh1_label = test_img('semi_anlayic/raif_img/1006_a0.42_i197.00 _rt9.13.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b74a865e-5297-408b-8d1d-442ebb7988e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(u94_Rh1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5309fbcf-43fe-4ff3-ad4f-9014a2b8dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=np.array(u94_Rh1_data)\n",
    "label=np.array(u94_Rh1_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fef5d0bc-87d3-49a5-8864-8a3dc8902cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RhDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x=train_data\n",
    "        self.y=label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5e83dcb-5b85-48f0-b0c1-2e386d9682d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = RhDataset()\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True,num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e83185f-9010-4734-8cf3-d2ba141fc629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "        # A batch consists of image data and corresponding labels.\n",
    "        imgs, labels = batch\n",
    "        imgs = imgs.float()\n",
    "        imgs = imgs.permute(0, 3, 1, 2)\n",
    "        #imgs = torch.unsqueeze(imgs, dim=0)  # 在第0维上增加一个维度\n",
    "        \n",
    "        # We don't need gradient in validation.\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            test_pred = model_best(imgs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "736c3aa0-3722-4a44-a7ed-184ab5287dfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true label is  [42.0]\n",
      "predict label is tensor([42])\n"
     ]
    }
   ],
   "source": [
    "print('true label is ',u94_Rh1_label)\n",
    "print('predict label is',test_pred.argmax(dim=-1).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2834dab4-61a0-4198-9d3b-26ac0eb30c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
